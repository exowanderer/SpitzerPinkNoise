{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pink Noise is 1/f noise\n",
    "\n",
    "This simulator will generate pink noise and attempt to mitigate it using wavelets and gaussian processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"]      = 300\n",
    "rcParams[\"figure.dpi\"]       = 300\n",
    "rcParams['errorbar.capsize'] = 0.0\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "from __future__ import absolute_import, unicode_literals, print_function\n",
    "import pymultinest\n",
    "import math\n",
    "import os\n",
    "import threading, subprocess\n",
    "\n",
    "from astroML.plotting import hist\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "from pylab import *;ion()\n",
    "\n",
    "from time import time\n",
    "\n",
    "from pymultinest.solve import Solver,solve\n",
    "\n",
    "if not os.path.exists(\"chains\"): os.mkdir(\"chains\")\n",
    "\n",
    "from celerite import plot_setup\n",
    "plot_setup.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Processes with Celerite \"first\" example**\n",
    "\n",
    "https://github.com/dfm/celerite/blob/master/docs/_static/notebooks/first.ipynb\n",
    "\n",
    "**Pink Noise Generator**\n",
    "\n",
    "https://github.com/python-acoustics/python-acoustics/blob/master/acoustics/generator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Processes for 1D Gaussian Fitting**\n",
    "\n",
    "**SHOTerm PSD**\n",
    "\n",
    "$$S(\\omega) = \\sqrt{\\frac{2}{\\pi}} \\frac{S_0\\,\\omega_0^4}\n",
    "    {(\\omega^2-{\\omega_0}^2)^2 + {\\omega_0}^2\\,\\omega^2/Q^2}$$\n",
    "    \n",
    "**Real Term PSD**\n",
    "$$k(\\tau) = a_j\\,e^{-c_j\\,\\tau}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ms(x):\n",
    "    \"\"\"Mean value of signal `x` squared.\n",
    "    :param x: Dynamic quantity.\n",
    "    :returns: Mean squared of `x`.\n",
    "    \n",
    "    Source: https://github.com/python-acoustics/python-acoustics/blob/master/acoustics/generator.py\n",
    "    \"\"\"\n",
    "    return (np.abs(x)**2.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(y, x=None):\n",
    "    \"\"\"normalize power in y to a (standard normal) white noise signal.\n",
    "    Optionally normalize to power in signal `x`.\n",
    "    #The mean power of a Gaussian with :math:`\\\\mu=0` and :math:`\\\\sigma=1` is 1.\n",
    "    \n",
    "    Source: https://github.com/python-acoustics/python-acoustics/blob/master/acoustics/generator.py\n",
    "    \"\"\"\n",
    "    #return y * np.sqrt( (np.abs(x)**2.0).mean() / (np.abs(y)**2.0).mean() )\n",
    "    if x is not None:\n",
    "        x = ms(x)\n",
    "    else:\n",
    "        x = 1.0\n",
    "    return y * np.sqrt( x / ms(y) )\n",
    "    #return y * np.sqrt( 1.0 / (np.abs(y)**2.0).mean() )\n",
    "    ## Broken? Caused correlation in auralizations....weird!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pink(N, state=None):\n",
    "    \"\"\"\n",
    "    Pink noise. \n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Pink noise has equal power in bands that are proportionally wide.\n",
    "    Power density decreases with 3 dB per octave.\n",
    "    \n",
    "    Source: https://github.com/python-acoustics/python-acoustics/blob/master/acoustics/generator.py\n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y),S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "nPts    = 50000\n",
    "tinky   = linspace(0,10,nPts)\n",
    "\n",
    "rstate = np.random.RandomState()\n",
    "pinky , Sinky   = pink(nPts, state=rstate)\n",
    "pinky2, Sinky2  = pink(nPts, state=rstate)\n",
    "\n",
    "ginky   = np.random.normal(0,1,nPts)\n",
    "pinkyC  = pinky + ginky\n",
    "\n",
    "yerrMin  = 0.08\n",
    "yerrMax  = 1.0\n",
    "yerrinky = np.random.uniform(yerrMin, yerrMax, len(tinky))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tinky,pinky,alpha=0.5);\n",
    "plt.plot(tinky,pinky2,alpha=0.5);\n",
    "# plt.plot(tinky[1:],np.diff(pinky),alpha=0.5);\n",
    "# plt.plot(tinky[1:],np.diff(pinky2),alpha=0.5);\n",
    "# plt.plot(tinky,ginky,alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSDinky = (np.fft.fftshift(np.fft.fft(pinky))[nPts//2:]).real**2\n",
    "PSDinky2= (np.fft.fftshift(np.fft.fft(pinky2))[nPts//2:]).real**2\n",
    "GSinky  = (np.fft.fftshift(np.fft.fft(ginky))[nPts//2:]).real**2\n",
    "loglog(Sinky[1:],PSDinky);\n",
    "loglog(Sinky[1:],PSDinky2);\n",
    "# loglog(Sinky[1:],GSinky);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglog(1/Sinky[1:],PSDinky);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "\n",
    "def quasi_periodic_oscillation(abscissa, coeffs, phaseOffset = 5):\n",
    "    assert(len(coeffs) == 4)\n",
    "    t = abscissa\n",
    "    c = coeffs\n",
    "    po= phaseOffset\n",
    "    return c[0] * (t-po) + c[1]*np.sin(c[2]*t + c[3]*(t-po)**2) + c[4]*np.cos(c[2]*t + c[3]*(t-po)**2)\n",
    "\n",
    "def fourier_function(abscissa, coeffs):\n",
    "    assert(len(coeffs) == 3)\n",
    "    t = abscissa\n",
    "    c = coeffs\n",
    "    return c[0]*np.sin(c[1]*t) + c[2]*np.cos(c[1]*t) \n",
    "\n",
    "t = np.sort(np.append(\n",
    "    np.random.uniform(0, 3.8, 57),\n",
    "    np.random.uniform(5.5, 10, 68),\n",
    "))  # The input coordinates must be sorted\n",
    "yerr = np.random.uniform(0.08, 0.22, len(t))\n",
    "# y = 0.2 * (t-5) + np.sin(3*t + 0.1*(t-5)**2) + yerr * np.random.randn(len(t))\n",
    "\n",
    "params1 = [.5, 3,.5]\n",
    "params2 = [.25, 3/2,.25]\n",
    "\n",
    "true_t = np.linspace(0, 10, 5000)\n",
    "# true_y = 0.2 * (true_t-5) + np.sin(3*true_t + 0.1*(true_t-5)**2)\n",
    "\n",
    "true_y = fourier_function(true_t, params1)+fourier_function(true_t, params2)\n",
    "y = fourier_function(t, params1)+fourier_function(t, params2) + yerr * np.random.randn(len(t))\n",
    "\n",
    "plt.plot(true_t, true_y, \"k\", lw=1.5, alpha=0.3)\n",
    "plt.errorbar(t, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(-1.25, 1.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import celerite\n",
    "from celerite import terms\n",
    "\n",
    "# A non-periodic component\n",
    "Q = 1.0 / np.sqrt(2.0)\n",
    "w0 = 3.0\n",
    "S0 = np.var(y) / (w0 * Q)\n",
    "\n",
    "logS0Range = -15, 15\n",
    "logQRange  = -15, 15\n",
    "logOmRange = -15, 15\n",
    "\n",
    "bounds = dict(log_S0=logS0Range, log_Q=logQRange, log_omega0=logOmRange)\n",
    "\n",
    "kernel = terms.SHOTerm(log_S0=np.log(S0), log_Q=np.log(Q), log_omega0=np.log(w0), bounds=bounds)\n",
    "kernel.freeze_parameter(\"log_Q\")  # We don't want to fit for \"Q\" in this term\n",
    "\n",
    "# A periodic component\n",
    "Q = 1.0\n",
    "w0 = 3.0\n",
    "S0 = np.var(y) / (w0 * Q)\n",
    "kernel += terms.SHOTerm(log_S0=np.log(S0), log_Q=np.log(Q), log_omega0=np.log(w0),\n",
    "                        bounds=bounds)\n",
    "\n",
    "# A periodic component\n",
    "Q = 1.0\n",
    "w0 = 3.0\n",
    "S0 = np.var(y) / (w0 * Q)\n",
    "kernel += terms.SHOTerm(log_S0=np.log(S0), log_Q=np.log(Q), log_omega0=np.log(w0),\n",
    "                        bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y    = pinky\n",
    "t    = tinky\n",
    "yerr = yerrinky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = celerite.GP(kernel, mean=np.mean(y))\n",
    "gp.compute(t, yerr)  # You always need to call compute once.\n",
    "print(\"Initial log likelihood: {0}\".format(gp.log_likelihood(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "cnt = 0\n",
    "def neg_log_like(params, y, gp):\n",
    "    global cnt\n",
    "    cnt+=1\n",
    "    gp.set_parameter_vector(params)\n",
    "    return -gp.log_likelihood(y)\n",
    "\n",
    "initial_params = gp.get_parameter_vector()\n",
    "bounds         = gp.get_parameter_bounds()\n",
    "\n",
    "start = time()\n",
    "r = minimize(neg_log_like, initial_params, method=\"L-BFGS-B\", bounds=bounds, args=(y, gp))\n",
    "end = time()\n",
    "\n",
    "gp.set_parameter_vector(r.x)\n",
    "print(r)\n",
    "print(\"Operation took {0:.2e} seconds and checked the LL {1:d} times\".format(end-start, cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPtsBIG = 5000\n",
    "x = np.linspace(t.min(), t.max(), nPtsBIG)\n",
    "pred_mean, pred_var = gp.predict(y, x, return_var=True)\n",
    "pred_std = np.sqrt(pred_var)\n",
    "\n",
    "print(np.isnan(pred_mean).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean_data2, pred_var_data2 = gp.predict(y, t)\n",
    "imshow(pred_var_data2, norm=LogNorm());\n",
    "title('Data Covariance Matrix',fontsize=10);\n",
    "colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = \"#ff7f0e\"\n",
    "plt.errorbar(t, y, yerr=yerr, fmt=\".k\", capsize=0);\n",
    "plt.plot(x, pred_mean, color=color);\n",
    "plt.fill_between(x, pred_mean+pred_std, pred_mean-pred_std, color=color, alpha=0.3,\n",
    "                 edgecolor=\"none\");\n",
    "plt.xlabel(\"x\");\n",
    "plt.ylabel(\"y\");\n",
    "# plt.xlim(0,10);\n",
    "# plt.ylim(-2.5, 2.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean_data, pred_var_data = gp.predict(y, t, return_var=True)\n",
    "plt.errorbar(t, y - pred_mean_data, yerr=yerr, fmt=\".k\", capsize=0);\n",
    "plt.fill_between(x, 0+pred_std, 0-pred_std, color=color, alpha=0.3, edgecolor=\"none\");\n",
    "\n",
    "# ylim(-2,2)\n",
    "# xlim(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroML.plotting import hist\n",
    "nbins = y.size//10\n",
    "hist(y-median(y), bins='blocks', normed=True, alpha=0.5);\n",
    "hist(y-pred_mean_data, bins='blocks', normed=True, alpha=0.5);\n",
    "xlim(-2,2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSDinky = (np.fft.fftshift(np.fft.fft(y-median(y)))[nPts//2:]).real**2\n",
    "PSDRes= (np.fft.fftshift(np.fft.fft(y-pred_mean_data))[nPts//2:]).real**2\n",
    "loglog(PSDinky);\n",
    "loglog(PSDRes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.exp(np.linspace(np.log(0.1), np.log(2000), 5000))\n",
    "psd = gp.kernel.get_psd(omega)\n",
    "\n",
    "plt.plot(omega, psd, color=color)\n",
    "# for k in gp.kernel.terms:\n",
    "#     plt.plot(omega, k.get_psd(omega), \"--\", color=color)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(omega[0], omega[-1])\n",
    "plt.xlabel(\"$\\omega$\")\n",
    "plt.ylabel(\"$S(\\omega)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Processes for 1D Gaussian Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian1Dp(cube):\n",
    "    center = cube[0]\n",
    "    width  = cube[1]\n",
    "    height = cube[2]\n",
    "    return lambda y: height*np.exp(-0.5*(( (center - y) / width)**2))# / sqrt(2*pi*width**2)\n",
    "\n",
    "def gaussian1D(cube):\n",
    "    center = cube[0]\n",
    "    width  = cube[1]\n",
    "    return lambda y: np.exp(-0.5*(( (center - y) / width)**2)) / sqrt(2*pi*width**2)\n",
    "\n",
    "def straight_line(cube):\n",
    "    offset = cube[0]\n",
    "    slope  = cube[1]\n",
    "    return lambda abscissa: offset + slope * abscissa\n",
    "\n",
    "def sine_wave(cube):\n",
    "    amp    = cube[0]\n",
    "    period = cube[1]\n",
    "    return lambda abscissa: amp*sin(2*pi / period * abscissa)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "param0a= -0.5#0.05\n",
    "param0b= 0.5#0.05\n",
    "param1a= 0.1#5*pi\n",
    "param1b= 0.1#5*pi\n",
    "param2a= 0.8\n",
    "param2b= 0.8\n",
    "\n",
    "yunc  = 0.1\n",
    "nPts  = int(100)\n",
    "nThPts= int(1e3)\n",
    "\n",
    "xmin  = -1#*pi\n",
    "xmax  =  1#*pi\n",
    "dx    = 0.1*(xmax - xmin)\n",
    "\n",
    "# model = sine_wave; parameters = [\"amp\", \"period\"]\n",
    "# model = straight_line; parameters = [\"offset\", \"slope\"]\n",
    "# model = gaussian1D; parameters = [\"center\", \"width\"]\n",
    "model = gaussian1Dp; parameters = [\"center\", \"width\", \"height\"]\n",
    "\n",
    "yuncs = np.random.normal(yunc, 1e-2 * yunc, nPts)\n",
    "true_t= np.linspace(xmin-dx, xmax+dx, nThPts)\n",
    "\n",
    "# xdata = np.linspace(xmin,xmax,nPts)\n",
    "t = sort(np.random.uniform(xmin, xmax, nPts))\n",
    "ydata = model([param0a,param1a,param2a])(t) + model([param0b,param1b,param2b])(t)\n",
    "\n",
    "yerr  = np.random.normal(0, yuncs, nPts)\n",
    "y = yerr + ydata# + yerr\n",
    "\n",
    "true_y  = model([param0a,param1a,param2a])(true_t) + model([param0b,param1b,param2b])(true_t)\n",
    "\n",
    "figure()#figsize=(10,10));\n",
    "plot(true_t, true_y, color=\"#424242\");\n",
    "errorbar(t, y, yunc*ones(y.size), fmt='o', color = \"#ff7f0e\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SHOTerm PSD**\n",
    "\n",
    "$$S(\\omega) = \\sqrt{\\frac{2}{\\pi}} \\frac{S_0\\,\\omega_0^4}\n",
    "    {(\\omega^2-{\\omega_0}^2)^2 + {\\omega_0}^2\\,\\omega^2/Q^2}$$\n",
    "    \n",
    "**Real Term PSD**\n",
    "$$k(\\tau) = a_j\\,e^{-c_j\\,\\tau}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import celerite\n",
    "from celerite import terms\n",
    "\n",
    "# A non-periodic component\n",
    "Q  = 1.0 / np.sqrt(2.0)\n",
    "w0 = 3.0\n",
    "S0 = np.var(y) / (w0 * Q)\n",
    "bounds = dict(log_a=(-15, 15), log_c=(-15, 15))\n",
    "kernelR = terms.RealTerm(log_a=np.log(S0), log_c=np.log(Q),bounds=bounds)\n",
    "kernelS = terms.SHOTerm(log_S0=np.log(S0), log_Q=np.log(Q), log_omega0=np.log(w0),bounds=bounds)\n",
    "\n",
    "kernelS.freeze_parameter(\"log_Q\")  # We don't want to fit for \"Q\" in this term\n",
    "\n",
    "# # A periodic component\n",
    "# Q = 1.0\n",
    "# w0 = 3.0\n",
    "# S0 = np.var(y) / (w0 * Q)\n",
    "# kernelRS = terms.SHOTerm(log_S0=np.log(S0), log_Q=np.log(Q), log_omega0=np.log(w0),bounds=bounds)+\\\n",
    "#            terms.SHOTerm(log_S0=np.log(S0), log_Q=np.log(Q), log_omega0=np.log(w0),bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A non-periodic component\n",
    "Q = 1.0 / np.sqrt(2.0)\n",
    "w0 = 3.0\n",
    "S0 = np.var(y) / (w0 * Q)\n",
    "boundsRS = dict(log_S0=(-15, 15), log_Q=(-15, 15), log_omega0=(-15, 15))\n",
    "kernelRS = terms.SHOTerm(log_S0=np.log(S0), log_Q=np.log(Q), log_omega0=np.log(w0),\n",
    "                       bounds=bounds)\n",
    "kernelRS.freeze_parameter(\"log_Q\")  # We don't want to fit for \"Q\" in this term\n",
    "\n",
    "# A periodic component\n",
    "Q = 1.0\n",
    "w0 = 3.0\n",
    "S0 = np.var(y) / (w0 * Q)\n",
    "kernelRS += terms.SHOTerm(log_S0=np.log(S0), log_Q=np.log(Q), log_omega0=np.log(w0),\n",
    "                        bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpR = celerite.GP(kernelR, mean=np.mean(y))\n",
    "gpR.compute(t, yerr)  # You always need to call compute once.\n",
    "print(\"Initial log likelihood: {0}\".format(gpR.log_likelihood(y)))\n",
    "\n",
    "gpS = celerite.GP(kernelS, mean=np.mean(y))\n",
    "gpS.compute(t, yerr)  # You always need to call compute once.\n",
    "print(\"Initial log likelihood: {0}\".format(gpS.log_likelihood(y)))\n",
    "\n",
    "gpRS = celerite.GP(kernelRS, mean=np.mean(y))\n",
    "gpRS.compute(t, yerr)  # You always need to call compute once.\n",
    "print(\"Initial log likelihood: {0}\".format(gpRS.log_likelihood(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"REAL\")\n",
    "print(\"parameter_dict:\\n{0}\\n\".format(gpR.get_parameter_dict()))\n",
    "print(\"parameter_names:\\n{0}\\n\".format(gpR.get_parameter_names()))\n",
    "print(\"parameter_vector:\\n{0}\\n\".format(gpR.get_parameter_vector()))\n",
    "print(\"parameter_bounds:\\n{0}\\n\".format(gpR.get_parameter_bounds()))\n",
    "print()\n",
    "print(\"SHO\")\n",
    "print(\"parameter_dict:\\n{0}\\n\".format(gpS.get_parameter_dict()))\n",
    "print(\"parameter_names:\\n{0}\\n\".format(gpS.get_parameter_names()))\n",
    "print(\"parameter_vector:\\n{0}\\n\".format(gpS.get_parameter_vector()))\n",
    "print(\"parameter_bounds:\\n{0}\\n\".format(gpS.get_parameter_bounds()))\n",
    "print()\n",
    "print(\"R+SHO\")\n",
    "print(\"parameter_dict:\\n{0}\\n\".format(gpRS.get_parameter_dict()))\n",
    "print(\"parameter_names:\\n{0}\\n\".format(gpRS.get_parameter_names()))\n",
    "print(\"parameter_vector:\\n{0}\\n\".format(gpRS.get_parameter_vector()))\n",
    "print(\"parameter_bounds:\\n{0}\\n\".format(gpRS.get_parameter_bounds()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(gp.get_parameter_names())\n",
    "gp.freeze_parameter(\"kernel:log_S0\")\n",
    "print(gp.get_parameter_names())\n",
    "gp.thaw_parameter(\"kernel:log_S0\")\n",
    "print(gp.get_parameter_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def neg_log_like(params, y, gp):\n",
    "    gsnow = gaussian1Dp(params[:2])\n",
    "    gp.set_parameter_vector(params[2:])\n",
    "    return -gp.log_likelihood(y-gsnow)\n",
    "\n",
    "# def neg_log_likeR(params, y, gp):\n",
    "#     gpR.set_parameter_vector(params)\n",
    "#     return -gpR.log_likelihood(y)\n",
    "\n",
    "# def neg_log_likeS(params, y, gp):\n",
    "#     gpS.set_parameter_vector(params)\n",
    "#     return -gpS.log_likelihood(y)\n",
    "\n",
    "# def neg_log_likeRS(params, y, gp):\n",
    "#     gpS.set_parameter_vector(params)\n",
    "#     return -gpS.log_likelihood(y)\n",
    "\n",
    "initial_paramsR = gpR.get_parameter_vector()\n",
    "initial_paramsS = gpS.get_parameter_vector()\n",
    "initial_paramsRS = gpRS.get_parameter_vector()\n",
    "boundsR = gpR.get_parameter_bounds()\n",
    "boundsS = gpS.get_parameter_bounds()\n",
    "boundsRS = gpRS.get_parameter_bounds()\n",
    "\n",
    "rR = minimize(neg_log_like, initial_paramsR , method=\"L-BFGS-B\", bounds=boundsR , args=(y, gpR ))\n",
    "rS = minimize(neg_log_like, initial_paramsS , method=\"L-BFGS-B\", bounds=boundsS , args=(y, gpS ))\n",
    "rRS= minimize(neg_log_like, initial_paramsRS, method=\"L-BFGS-B\", bounds=boundsRS, args=(y, gpRS))\n",
    "\n",
    "gpR.set_parameter_vector(rR.x)\n",
    "gpS.set_parameter_vector(rS.x)\n",
    "gpRS.set_parameter_vector(rRS.x)\n",
    "print(rR)\n",
    "print()\n",
    "print(rS)\n",
    "print()\n",
    "print(rRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpR.get_parameter_dict(),gpS.get_parameter_dict(),gpRS.get_parameter_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1.1, 1.1, 1000)\n",
    "pred_meanR, cov_varR = gpR.predict(y, x)\n",
    "pred_meanR, pred_varR = gpR.predict(y, x, return_var=True)\n",
    "pred_stdR = np.sqrt(pred_varR)\n",
    "\n",
    "pred_meanS, cov_varS = gpS.predict(y, x)\n",
    "pred_meanS, pred_varS = gpS.predict(y, x, return_var=True)\n",
    "pred_stdS = np.sqrt(pred_varS)\n",
    "\n",
    "pred_meanRS, cov_varRS = gpRS.predict(y, x)\n",
    "pred_meanRS, pred_varRS = gpRS.predict(y, x, return_var=True)\n",
    "pred_stdRS = np.sqrt(pred_varRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure()\n",
    "imshow(cov_varS);\n",
    "colorbar()\n",
    "title('S Data Covariance Matrix');\n",
    "\n",
    "figure()\n",
    "imshow(cov_varR);\n",
    "colorbar()\n",
    "title('R Data Covariance Matrix');\n",
    "\n",
    "figure()\n",
    "imshow(cov_varRS);\n",
    "colorbar()\n",
    "title('RS Data Covariance Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure()\n",
    "_, cov_var_dataS = gpS.predict(y, t)\n",
    "imshow(cov_var_dataS);\n",
    "colorbar()\n",
    "title('S Data Covariance Matrix');\n",
    "\n",
    "figure()\n",
    "_, cov_var_dataR = gpR.predict(y, t)\n",
    "imshow(cov_var_dataR);\n",
    "colorbar()\n",
    "title('R Data Covariance Matrix');\n",
    "\n",
    "figure()\n",
    "_, cov_var_dataRS = gpRS.predict(y, t)\n",
    "imshow(cov_var_dataRS);\n",
    "colorbar()\n",
    "title('RS Data Covariance Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = \"#ff7f0e\"\n",
    "plt.plot(true_t, true_y, \"k\", lw=1.5, alpha=0.3)\n",
    "plt.errorbar(t, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "plt.plot(x, pred_meanS, color=color)\n",
    "plt.fill_between(x, pred_meanS+pred_stdS, pred_meanS-pred_stdS, color=color, alpha=0.3,\n",
    "                 edgecolor=\"none\")\n",
    "\n",
    "# plt.plot(true_t, true_y, \"k\", lw=1.5, alpha=0.3)\n",
    "plt.errorbar(t, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "plt.plot(x, pred_meanR, color='violet')\n",
    "plt.fill_between(x, pred_meanR+pred_stdR, pred_meanR-pred_stdR, color='violet', alpha=0.3,\n",
    "                 edgecolor=\"none\")\n",
    "\n",
    "plt.errorbar(t, y, yerr=yerr, fmt=\".k\", capsize=0)\n",
    "plt.plot(x, pred_meanRS, color='gold')\n",
    "plt.fill_between(x, pred_meanRS+pred_stdRS, pred_meanRS-pred_stdRS, color='gold', alpha=0.3,\n",
    "                 edgecolor=\"none\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlim(-1.1,1.1)\n",
    "plt.ylim(-0.5, 1.25);\n",
    "\n",
    "figure()\n",
    "plt.semilogy(true_t, abs(true_y-pred_meanS)/true_y, c=color   )\n",
    "plt.semilogy(true_t, abs(true_y-pred_meanR)/true_y, c=\"violet\")\n",
    "plt.semilogy(true_t, abs(true_y-pred_meanRS)/true_y, c=\"gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.exp(np.linspace(np.log(0.1), np.log(20), 5000))\n",
    "psdR = gpR.kernel.get_psd(omega)\n",
    "psdS = gpS.kernel.get_psd(omega)\n",
    "psdRS= gpRS.kernel.get_psd(omega)\n",
    "\n",
    "plt.plot(omega, psdR , color=color)\n",
    "plt.plot(omega, psdS , color=\"violet\")\n",
    "plt.plot(omega, psdRS, color=\"gold\")\n",
    "\n",
    "for k in gpR.kernel.terms:\n",
    "    plt.plot(omega, k.get_psd(omega), \"--\", color=color)\n",
    "\n",
    "for k in gpS.kernel.terms:\n",
    "    plt.plot(omega, k.get_psd(omega), \"--\", color=color)\n",
    "\n",
    "for k in gpRS.kernel.terms:\n",
    "    plt.plot(omega, k.get_psd(omega), \"--\", color=color)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(omega[0], omega[-1])\n",
    "plt.xlabel(\"$\\omega$\")\n",
    "plt.ylabel(\"$S(\\omega)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** MultiModel Gaussian Normal in 1D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian1Dp(cube):\n",
    "    center = cube[0]\n",
    "    width  = cube[1]\n",
    "    height = cube[2]\n",
    "    return lambda y: height*np.exp(-0.5*(( (center - y) / width)**2))# / sqrt(2*pi*width**2)\n",
    "\n",
    "def gaussian1D(cube):\n",
    "    center = cube[0]\n",
    "    width  = cube[1]\n",
    "    return lambda y: np.exp(-0.5*(( (center - y) / width)**2)) / sqrt(2*pi*width**2)\n",
    "\n",
    "def straight_line(cube):\n",
    "    offset = cube[0]\n",
    "    slope  = cube[1]\n",
    "    return lambda abscissa: offset + slope * abscissa\n",
    "\n",
    "def sine_wave(cube):\n",
    "    amp    = cube[0]\n",
    "    period = cube[1]\n",
    "    return lambda abscissa: amp*sin(2*pi / period * abscissa)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "param0a= -0.5#0.05\n",
    "param0b= 0.5#0.05\n",
    "param1a= 0.1#5*pi\n",
    "param1b= 0.1#5*pi\n",
    "param2a= 0.8\n",
    "param2b= 0.8\n",
    "\n",
    "yunc  = 0.1\n",
    "nPts  = int(100)\n",
    "nThPts= int(1e3)\n",
    "\n",
    "xmin  = -1#*pi\n",
    "xmax  =  1#*pi\n",
    "dx    = 0.1*(xmax - xmin)\n",
    "\n",
    "# model = sine_wave; parameters = [\"amp\", \"period\"]\n",
    "# model = straight_line; parameters = [\"offset\", \"slope\"]\n",
    "# model = gaussian1D; parameters = [\"center\", \"width\"]\n",
    "model = gaussian1Dp; parameters = [\"center\", \"width\", \"height\"]\n",
    "\n",
    "yuncs = np.random.normal(yunc, 1e-2 * yunc, nPts)\n",
    "true_t= np.linspace(xmin-dx, xmax+dx, nThPts)\n",
    "\n",
    "# xdata = np.linspace(xmin,xmax,nPts)\n",
    "t = sort(np.random.uniform(xmin, xmax, nPts))\n",
    "ydata = model([param0a,param1a,param2a])(xdata) + model([param0b,param1b,param2b])(xdata)\n",
    "\n",
    "yerr  = np.random.normal(0, yuncs, nPts)\n",
    "y = ydata + yerr\n",
    "\n",
    "true_y  = model([param0a,param1a,param2a])(thdata) + model([param0b,param1b,param2b])(thdata)\n",
    "\n",
    "figure(figsize=(10,10));\n",
    "plot(true_t, true_y);\n",
    "errorbar(xdata, zdata, yunc*ones(zdata.size), fmt='o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prior(cube, ndim, nparams):\n",
    "    cube[0] = cube[0]*2 - 1\n",
    "    cube[1] = cube[1]*2\n",
    "    cube[2] = cube[2]*2\n",
    "    pass\n",
    "\n",
    "def loglike(cube, ndim, nparams):\n",
    "    modelNow = model(cube)(xdata)\n",
    "    return -0.5*((modelNow - ydata)**2. / yuncs**2.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"chains\"): os.mkdir(\"chains\")\n",
    "\n",
    "n_params = len(parameters)\n",
    "\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "\n",
    "# we want to see some output while it is running\n",
    "progress = pymultinest.ProgressPlotter(n_params = n_params, outputfiles_basename=outputfiles_basename); progress.start()\n",
    "# threading.Timer(2, show, [\"chains/2-phys_live.points.pdf\"]).start() # delayed opening\n",
    "# run MultiNest\n",
    "pymultinest.run(loglike, prior, n_params, importance_nested_sampling = False, resume = False, verbose = True, \\\n",
    "            sampling_efficiency = 'parameter', n_live_points = 1000, outputfiles_basename=outputfiles_basename)\n",
    "\n",
    "'''\n",
    "sampling_efficiency == 'parameter' for parameter estimation\n",
    "sampling_efficiency == 'model'     for model selection\n",
    "'''\n",
    "\n",
    "# ok, done. Stop our progress watcher\n",
    "progress.stop()\n",
    "\n",
    "# lets analyse the results\n",
    "a = pymultinest.Analyzer(n_params = n_params, outputfiles_basename=outputfiles_basename)\n",
    "s = a.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"Global Evidence:\\n\\t%.15e +- %.15e\" % ( s['nested sampling global log-evidence'], s['nested sampling global log-evidence error'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "\n",
    "# Here we will plot all the marginals and whatnot, just to show off\n",
    "# You may configure the format of the output here, or in matplotlibrc\n",
    "# All pymultinest does is filling in the data of the plot.\n",
    "\n",
    "# Copy and edit this file, and play with it.\n",
    "\n",
    "p = pymultinest.PlotMarginalModes(a)\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "for i in range(n_params):\n",
    "    plt.subplot(n_params, n_params, n_params * i + i + 1)\n",
    "    p.plot_marginal(i, with_ellipses = True, with_points = False, grid_points=50)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    \n",
    "    for j in range(i):\n",
    "        plt.subplot(n_params, n_params, n_params * j + i + 1)\n",
    "        #plt.subplots_adjust(left=0, bottom=0, right=0, top=0, wspace=0, hspace=0)\n",
    "        p.plot_conditional(i, j, with_ellipses = False, with_points = True, grid_points=30)\n",
    "        plt.xlabel(parameters[i])\n",
    "        plt.ylabel(parameters[j])\n",
    "\n",
    "# plt.savefig(\"chains/marginals_multinest.pdf\") #, bbox_inches='tight')\n",
    "# show(\"chains/marginals_multinest.pdf\")\n",
    "\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "plt.subplot2grid((5*n_params, 5*n_params), loc=(0,0))\n",
    "for i in range(n_params):\n",
    "    #plt.subplot(n_params, n_params, i + 1)\n",
    "    # outfile = '%s-mode-marginal-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p.plot_modes_marginal(i, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "    \n",
    "    # outfile = '%s-mode-marginal-cumulative-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p.plot_modes_marginal(i, cumulative = True, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Cumulative probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "\n",
    "print(\"Take a look at the pdf files in chains/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('best\\t', np.round(p.analyser.get_best_fit()['parameters'],3))\n",
    "for k,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    print('mode' + str(k) + '\\t', np.round(mode['mean'],3))\n",
    "\n",
    "print('True a\\t', [param0a, param1a])\n",
    "print('True b\\t', [param0b, param1b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.analyser.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "errorbar(xdata, zdata, yunc*ones(zdata.size), fmt='o')\n",
    "modelAll = np.zeros(thdata.size)\n",
    "for m in p.analyser.get_stats()['modes']:\n",
    "    modelAll = modelAll + model(m['mean'])(thdata)\n",
    "    plot(thdata, model(m['mean'])(thdata))\n",
    "\n",
    "plot(thdata, modelAll)\n",
    "plot(thdata, model(p.analyser.get_best_fit()['parameters'])(thdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Simple MultiModel Gaussian Normal in 2D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *;ion()\n",
    "\n",
    "from pymultinest.solve import Solver,solve\n",
    "from numpy import pi, sin, cos, linspace\n",
    "\n",
    "def gaussian2D(cube):\n",
    "    center = cube[0]\n",
    "    width  = cube[1]\n",
    "    return lambda y,x: np.exp(-0.5*((( (center - y) / width)**2) + (( (center - x) / width)**2))) / sqrt(2*pi*width**2)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "param0a= 0.75#0.05\n",
    "param1a= 0.05#0.05\n",
    "param0b= 0.25#0.05\n",
    "param1b= 0.05#0.05\n",
    "\n",
    "# param2= 0.8\n",
    "\n",
    "yunc  = 0.1\n",
    "nPts  = int(100)\n",
    "nThPts= int(1e3)\n",
    "\n",
    "xmin  = -0#*pi\n",
    "xmax  =  1#*pi\n",
    "dx    = 0.1*(xmax - xmin)\n",
    "\n",
    "ymin  = -0#*pi\n",
    "ymax  =  1#*pi\n",
    "dy    = 0.1*(ymax - ymin)\n",
    "\n",
    "model = gaussian2D; parameters = [\"center\", \"width\"]\n",
    "\n",
    "yuncs = np.random.normal(yunc, 1e-2 * yunc, (nPts,nPts))\n",
    "# thdata= np.linspace(xmin-dx, xmax+dx, nThPts)\n",
    "\n",
    "xdata = np.ones((nPts,nPts))*np.linspace(xmin,xmax,nPts)\n",
    "ydata = (np.ones((nPts,nPts))*np.linspace(ymin,ymax,nPts)).T\n",
    "\n",
    "zmodel  = model([param0a,param1a])(ydata,xdata) + model([param0b,param1b])(ydata,xdata)\n",
    "zerr    = np.random.normal(0, yuncs, (nPts,nPts))\n",
    "zdata   = zmodel + zerr\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "imshow(zdata, extent=[xdata.min(), xdata.max(), ydata.min(), ydata.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "# model = sine_wave; parameters = [\"amp\", \"period\"]\n",
    "# model = gaussian1D; parameters = [\"center\", \"width\"]\n",
    "# model = straight_line; parameters = [\"offset\", \"slope\"]\n",
    "\n",
    "def prior(cube, ndim, nparams):\n",
    "    pass\n",
    "\n",
    "def loglike(cube, ndim, nparams):\n",
    "    modelNow = gaussian2D(cube)(ydata,xdata)\n",
    "    return -0.5*((modelNow - zdata)**2. / yuncs**2.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"chains\"): os.mkdir(\"chains\")\n",
    "\n",
    "# number of dimensions our problem has\n",
    "# parameters = [\"x\", \"y\"]\n",
    "n_params = len(parameters)\n",
    "\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "# we want to see some output while it is running\n",
    "progress = pymultinest.ProgressPlotter(n_params = n_params, outputfiles_basename=outputfiles_basename); progress.start()\n",
    "# threading.Timer(2, show, [\"chains/2-phys_live.points.pdf\"]).start() # delayed opening\n",
    "# run MultiNest\n",
    "pymultinest.run(loglike, prior, n_params, importance_nested_sampling = False, \\\n",
    "                resume = False, verbose = True, sampling_efficiency = 'model', n_live_points = 1000, \\\n",
    "                outputfiles_basename=outputfiles_basename)\n",
    "\n",
    "# ok, done. Stop our progress watcher\n",
    "progress.stop()\n",
    "\n",
    "# lets analyse the results\n",
    "a = pymultinest.Analyzer(n_params = n_params, outputfiles_basename=outputfiles_basename)\n",
    "s = a.get_stats()\n",
    "\n",
    "# fig = gcf()\n",
    "# axs  = fig.get_axes()\n",
    "# for ax in axs:\n",
    "#     ax.set_ylim(-16,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"Global Evidence:\\n\\t%.15e +- %.15e\" % ( s['nested sampling global log-evidence'], s['nested sampling global log-evidence error'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "\n",
    "# Here we will plot all the marginals and whatnot, just to show off\n",
    "# You may configure the format of the output here, or in matplotlibrc\n",
    "# All pymultinest does is filling in the data of the plot.\n",
    "\n",
    "# Copy and edit this file, and play with it.\n",
    "\n",
    "p = pymultinest.PlotMarginalModes(a)\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "for i in range(n_params):\n",
    "    plt.subplot(n_params, n_params, n_params * i + i + 1)\n",
    "    p.plot_marginal(i, with_ellipses = True, with_points = False, grid_points=50)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    \n",
    "    for j in range(i):\n",
    "        plt.subplot(n_params, n_params, n_params * j + i + 1)\n",
    "        #plt.subplots_adjust(left=0, bottom=0, right=0, top=0, wspace=0, hspace=0)\n",
    "        p.plot_conditional(i, j, with_ellipses = False, with_points = True, grid_points=30)\n",
    "        plt.xlabel(parameters[i])\n",
    "        plt.ylabel(parameters[j])\n",
    "\n",
    "# plt.savefig(\"chains/marginals_multinest.pdf\") #, bbox_inches='tight')\n",
    "# show(\"chains/marginals_multinest.pdf\")\n",
    "\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "plt.subplot2grid((5*n_params, 5*n_params), loc=(0,0))\n",
    "for i in range(n_params):\n",
    "    #plt.subplot(n_params, n_params, i + 1)\n",
    "    # outfile = '%s-mode-marginal-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p.plot_modes_marginal(i, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "    \n",
    "    # outfile = '%s-mode-marginal-cumulative-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p.plot_modes_marginal(i, cumulative = True, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Cumulative probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "\n",
    "print(\"Take a look at the pdf files in chains/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('best\\t', np.round(p.analyser.get_best_fit()['parameters'],3))\n",
    "for k,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    print('mode' + str(k) + '\\t', np.round(mode['mean'],3),'\\t', np.round(mode['local log-evidence'],3))\n",
    "\n",
    "print('True a\\t', [param0a, param1a])\n",
    "print('True b\\t', [param0b, param1b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelAll = np.zeros((nPts, nPts))\n",
    "fig=figure(figsize=(20,10))\n",
    "for km,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    modelAll = modelAll + model(mode['mean'])(ydata,xdata)\n",
    "    ax = fig.add_subplot(1,len(p.analyser.get_stats()['modes']), km+1)\n",
    "    ims = ax.imshow(model(mode['mean'])(ydata,xdata))\n",
    "    plt.colorbar(ims)\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(131)\n",
    "ims = ax.imshow(modelAll)\n",
    "plt.colorbar(ims)\n",
    "ax = fig.add_subplot(132)\n",
    "ims = ax.imshow(model(p.analyser.get_best_fit()['parameters'])(ydata,xdata))\n",
    "plt.colorbar(ims)\n",
    "ax = fig.add_subplot(133)\n",
    "ims = ax.imshow(zdata)\n",
    "plt.colorbar(ims)\n",
    "\n",
    "# Residuals\n",
    "modelAll = np.zeros((nPts, nPts))\n",
    "for km,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    if np.round(mode['local log-evidence'],3) > -400000.:\n",
    "        modelAll = modelAll + model(mode['mean'])(ydata,xdata)\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "ax  = fig.add_subplot(131)\n",
    "ims = ax.imshow(zdata - modelAll)\n",
    "plt.colorbar(ims)\n",
    "ax  = fig.add_subplot(132)\n",
    "ax.hist((zdata - modelAll).ravel(), bins=1000, normed=True);\n",
    "# plt.colorbar(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.analyser.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Full MultiModel Gaussian Normal in 2D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *;ion()\n",
    "\n",
    "from pymultinest.solve import Solver,solve\n",
    "from numpy import pi, sin, cos, linspace\n",
    "\n",
    "def gaussian2D(cube):\n",
    "    ycenter = cube[0]\n",
    "    xcenter = cube[1]\n",
    "    ywidth  = cube[2]\n",
    "    xwidth  = cube[3]\n",
    "    height  = cube[4]\n",
    "    offset  = cube[5]\n",
    "    return lambda y,x: height*np.exp(-0.5*((( (ycenter - y) / ywidth)**2) + (( (xcenter - x) / xwidth)**2))) + offset\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# param0a= 0.75#0.05\n",
    "# param1a= 0.05#0.05\n",
    "# param0b= 0.25#0.05\n",
    "# param1b= 0.05#0.05\n",
    "# param2= 0.8\n",
    "\n",
    "xcenter = 10.\n",
    "ycenter = 10.\n",
    "xwidth  = 1.0\n",
    "ywidth  = 1.0\n",
    "height  = 10.\n",
    "offset  = 1.0\n",
    "\n",
    "params1 = [ycenter, xcenter, ywidth, xwidth, height, offset]\n",
    "params2 = [ycenter+10, xcenter+10, ywidth, xwidth, height, offset]\n",
    "\n",
    "yunc  = 0.1\n",
    "nPts  = int(32)\n",
    "\n",
    "xmin  = -0#*pi\n",
    "xmax  =  nPts#*pi\n",
    "dx    = 0.1*(xmax - xmin)\n",
    "\n",
    "ymin  = -0#*pi\n",
    "ymax  =  nPts#*pi\n",
    "dy    = 0.1*(ymax - ymin)\n",
    "\n",
    "model = gaussian2D; parameters = [\"ycenter\", \"xcenter\", \"ywidth\", \"xwidth\", \"height\", \"offset\"]\n",
    "\n",
    "yuncs = np.random.normal(yunc, 1e-2 * yunc, (nPts,nPts))\n",
    "# thdata= np.linspace(xmin-dx, xmax+dx, nThPts)\n",
    "\n",
    "xdata = np.ones((nPts,nPts))*np.linspace(xmin,xmax,nPts)\n",
    "ydata = (np.ones((nPts,nPts))*np.linspace(ymin,ymax,nPts)).T\n",
    "\n",
    "zmodel  = model(params1)(ydata,xdata) + model(params2)(ydata,xdata)\n",
    "zerr    = np.random.normal(0, yuncs, (nPts,nPts))\n",
    "zdata   = zmodel + zerr\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "imshow(zdata)#, extent=[xdata.min(), xdata.max(), ydata.max(), ydata.min()])\n",
    "ylim(0,nPts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "# model = sine_wave; parameters = [\"amp\", \"period\"]\n",
    "# model = gaussian1D; parameters = [\"center\", \"width\"]\n",
    "# model = straight_line; parameters = [\"offset\", \"slope\"]\n",
    "\n",
    "def prior(cube, ndim, nparams):\n",
    "    cube[0] = cube[0]*xdata.max()\n",
    "    cube[1] = cube[1]*ydata.max()\n",
    "    cube[2] = cube[2]*2\n",
    "    cube[3] = cube[3]*2\n",
    "    cube[4] = cube[4]*20\n",
    "    cube[5] = cube[5]*10\n",
    "    return cube\n",
    "\n",
    "def loglike(cube, ndim, nparams):\n",
    "    modelNow = gaussian2D(cube)(ydata,xdata)\n",
    "    return -0.5*((modelNow - zdata)**2. / yuncs**2.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"chains\"): os.mkdir(\"chains\")\n",
    "\n",
    "# number of dimensions our problem has\n",
    "# parameters = [\"x\", \"y\"]\n",
    "n_params = len(parameters)\n",
    "\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "# we want to see some output while it is running\n",
    "progress = pymultinest.ProgressPlotter(n_params = n_params, outputfiles_basename=outputfiles_basename); progress.start()\n",
    "# threading.Timer(2, show, [\"chains/2-phys_live.points.pdf\"]).start() # delayed opening\n",
    "# run MultiNest\n",
    "pymultinest.run(loglike, prior, n_params, importance_nested_sampling = False, \\\n",
    "                resume = False, verbose = True, sampling_efficiency = 'model', n_live_points = 1000, \\\n",
    "                outputfiles_basename=outputfiles_basename)\n",
    "\n",
    "# ok, done. Stop our progress watcher\n",
    "progress.stop()\n",
    "\n",
    "# lets analyse the results\n",
    "a = pymultinest.Analyzer(n_params = n_params, outputfiles_basename=outputfiles_basename)\n",
    "s = a.get_stats()\n",
    "\n",
    "# fig = gcf()\n",
    "# axs  = fig.get_axes()\n",
    "# for ax in axs:\n",
    "#     ax.set_ylim(-16,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"Global Evidence:\\n\\t%.15e +- %.15e\" % ( s['nested sampling global log-evidence'], s['nested sampling global log-evidence error'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "\n",
    "# Here we will plot all the marginals and whatnot, just to show off\n",
    "# You may configure the format of the output here, or in matplotlibrc\n",
    "# All pymultinest does is filling in the data of the plot.\n",
    "\n",
    "# Copy and edit this file, and play with it.\n",
    "\n",
    "p = pymultinest.PlotMarginalModes(a)\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "for i in range(n_params):\n",
    "    plt.subplot(n_params, n_params, n_params * i + i + 1)\n",
    "    p.plot_marginal(i, with_ellipses = True, with_points = False, grid_points=50)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    \n",
    "    for j in range(i):\n",
    "        plt.subplot(n_params, n_params, n_params * j + i + 1)\n",
    "        #plt.subplots_adjust(left=0, bottom=0, right=0, top=0, wspace=0, hspace=0)\n",
    "        p.plot_conditional(i, j, with_ellipses = False, with_points = True, grid_points=30)\n",
    "        plt.xlabel(parameters[i])\n",
    "        plt.ylabel(parameters[j])\n",
    "\n",
    "# plt.savefig(\"chains/marginals_multinest.pdf\") #, bbox_inches='tight')\n",
    "# show(\"chains/marginals_multinest.pdf\")\n",
    "\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "plt.subplot2grid((5*n_params, 5*n_params), loc=(0,0))\n",
    "for i in range(n_params):\n",
    "    #plt.subplot(n_params, n_params, i + 1)\n",
    "    # outfile = '%s-mode-marginal-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p.plot_modes_marginal(i, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "    \n",
    "    # outfile = '%s-mode-marginal-cumulative-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p.plot_modes_marginal(i, cumulative = True, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Cumulative probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "\n",
    "print(\"Take a look at the pdf files in chains/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('best\\t', np.round(p.analyser.get_best_fit()['parameters'],3))\n",
    "for k,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    print('mode' + str(k) + '\\t', np.round(mode['mean'],3),'\\t', np.round(mode['local log-evidence'],3))\n",
    "\n",
    "print('True Mode 1\\t', params1)\n",
    "print('True Mode 2\\t', params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelAll = np.zeros((nPts, nPts))\n",
    "fig=figure(figsize=(20,10))\n",
    "for km,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    modelAll = modelAll + model(mode['mean'])(ydata,xdata)\n",
    "    ax = fig.add_subplot(1,len(p.analyser.get_stats()['modes']), km+1)\n",
    "    ims = ax.imshow(model(mode['mean'])(ydata,xdata))\n",
    "    plt.colorbar(ims)\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(131)\n",
    "ims = ax.imshow(modelAll)\n",
    "plt.colorbar(ims)\n",
    "ax = fig.add_subplot(132)\n",
    "ims = ax.imshow(model(p.analyser.get_best_fit()['parameters'])(ydata,xdata))\n",
    "plt.colorbar(ims)\n",
    "ax = fig.add_subplot(133)\n",
    "ims = ax.imshow(zdata)\n",
    "plt.colorbar(ims)\n",
    "\n",
    "# Residuals\n",
    "modelAll = np.zeros((nPts, nPts))\n",
    "for km,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    if np.round(mode['local log-evidence'],3) > -400000.:\n",
    "        modelAll = modelAll + model(mode['mean'])(ydata,xdata)\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "ax  = fig.add_subplot(131)\n",
    "ims = ax.imshow(zdata - modelAll - median(zdata - modelAll))\n",
    "plt.colorbar(ims)\n",
    "ax  = fig.add_subplot(132)\n",
    "ax.hist((zdata - modelAll - median(zdata - modelAll)).ravel(), bins=50, normed=True);\n",
    "ax.axvline(0.0, ls='--', c='k')\n",
    "# plt.colorbar(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p.analyser.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Star Field**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import, unicode_literals, print_function\n",
    "import pymultinest\n",
    "import math\n",
    "import os\n",
    "import threading, subprocess\n",
    "from sys import platform\n",
    "\n",
    "from pylab import *;ion()\n",
    "\n",
    "from time import time\n",
    "\n",
    "if not os.path.exists(\"chains\"): os.mkdir(\"chains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def gaussian2D(cube):\n",
    "    ycenter = cube[0]\n",
    "    xcenter = cube[1]\n",
    "    ywidth  = cube[2]\n",
    "    xwidth  = cube[3]\n",
    "    height  = cube[4]\n",
    "    offset  = cube[5]\n",
    "#     height = 10\n",
    "#     offset = 10\n",
    "#     xwidth = cube[2]\n",
    "#     ywidth = cube[2]\n",
    "    return lambda y,x: height*np.exp(-0.5*((( (ycenter - y) / ywidth)**2) + (( (xcenter - x) / xwidth)**2))) + offset\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "yunc  = 0.01\n",
    "nPts  = int(50)\n",
    "\n",
    "xmin  = -0#*pi\n",
    "xmax  =  nPts#*pi\n",
    "dx    = 0.1*(xmax - xmin)\n",
    "\n",
    "ymin  = -0#*pi\n",
    "ymax  =  nPts#*pi\n",
    "dy    = 0.1*(ymax - ymin)\n",
    "\n",
    "minwidth = 0.75\n",
    "maxwidth = 1.25\n",
    "minheight= 9.0\n",
    "maxheight= 10.0\n",
    "minoffset= 0.0\n",
    "maxoffset= 1.0\n",
    "\n",
    "nSig        = 10\n",
    "nStars      = 10\n",
    "cStars      = 0\n",
    "\n",
    "paramsList  = []\n",
    "while cStars < nStars:\n",
    "    xcenter = np.random.uniform(2*maxwidth, xmax - 2*maxwidth)\n",
    "    ycenter = np.random.uniform(2*maxwidth, ymax - 2*maxwidth)\n",
    "    width  = np.random.uniform(minwidth, maxwidth)\n",
    "    xwidth  = np.random.uniform(minwidth, maxwidth)\n",
    "    ywidth  = np.random.uniform(minwidth, maxwidth)\n",
    "    height  = np.random.uniform(minheight, maxheight)*0+10.\n",
    "    offset  = 0#np.random.uniform(minoffset, maxoffset)*0+.001\n",
    "    \n",
    "    # paramsNow = [ycenter, xcenter]#, width]#, ywidth, xwidth, height, offset]\n",
    "    paramsNow = [ycenter, xcenter, ywidth, xwidth, height, offset]\n",
    "    keep      = True\n",
    "    for k in range(len(paramsList)):\n",
    "        distNow = sqrt((paramsList[k][0] - paramsNow[0])**2. + (paramsList[k][1] - paramsNow[1])**2.)\n",
    "        widNow  = 1.#max([paramsList[k][2], paramsList[k][3], paramsNow[2], paramsNow[3]])\n",
    "        if distNow < nSig*widNow:\n",
    "            #print(k, distNow, nSig*widNow, (distNow - nSig*widNow))\n",
    "            keep = False\n",
    "    \n",
    "    if keep:\n",
    "        paramsList.append(paramsNow)\n",
    "        cStars += 1\n",
    "        print('Found',cStars,'stars at',np.round(paramsNow,3),)\n",
    "\n",
    "# model = gaussian2D; parameters = [\"ycenter\", \"xcenter\"]#, \"width\"]#, \"ywidth\", \"xwidth\", \"height\", \"offset\"]\n",
    "model = gaussian2D; parameters = [\"ycenter\", \"xcenter\", \"ywidth\", \"xwidth\", \"height\", \"offset\"]\n",
    "\n",
    "yuncs = np.random.normal(yunc, 1e-2 * yunc, (nPts,nPts))\n",
    "# thdata= np.linspace(xmin-dx, xmax+dx, nThPts)\n",
    "\n",
    "xdata = np.ones((nPts,nPts))*np.linspace(xmin,xmax,nPts)\n",
    "ydata = (np.ones((nPts,nPts))*np.linspace(ymin,ymax,nPts)).T\n",
    "\n",
    "zmodel  = np.zeros(xdata.shape)\n",
    "for paramsNow in paramsList:\n",
    "    zmodel += model(paramsNow)(ydata, xdata)\n",
    "\n",
    "znoise  = np.random.normal(0, yuncs, (nPts,nPts))\n",
    "zmodel -= median(zmodel)\n",
    "zdata   = zmodel + znoise\n",
    "\n",
    "zerr    = sqrt(abs(zdata))\n",
    "\n",
    "fig = figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ims1=ax1.imshow(zdata)#, extent=[xdata.min(), xdata.max(), ydata.max(), ydata.min()])\n",
    "ax1.set_ylim(0,nPts-1)\n",
    "\n",
    "divider1 = make_axes_locatable(ax1)\n",
    "cax1     = divider1.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar1    = plt.colorbar(ims1, cax=cax1, ticks=MultipleLocator(1), format=\"%.2f\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ims2=ax2.imshow(zerr)#, extent=[xdata.min(), xdata.max(), ydata.max(), ydata.min()])\n",
    "ax2.set_ylim(0,nPts-1)\n",
    "\n",
    "divider2 = make_axes_locatable(ax2)\n",
    "cax2     = divider2.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar2    = plt.colorbar(ims2, cax=cax2, ticks=MultipleLocator(0.2), format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Variable Subframes Inside logE **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subframe(dataIn, cube, nSig=10):\n",
    "    ycenter = cube[0]\n",
    "    xcenter = cube[1]\n",
    "    width   = cube[2]\n",
    "    \n",
    "    dataNow  = dataIn.copy()\n",
    "    ycenter  = np.int(np.round(ycenter))\n",
    "    xcenter  = np.int(np.round(xcenter))\n",
    "    width    = np.int(np.round(width))\n",
    "    \n",
    "    ylower = max([ycenter - nSig*width,0])\n",
    "    yupper = min([ycenter + nSig*width, ydata.max()])\n",
    "    xlower = max([xcenter - nSig*width,0])\n",
    "    xupper = min([xcenter + nSig*width, ydata.max()])\n",
    "    \n",
    "    return dataNow[ylower:yupper, xlower:xupper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from photutils import CircularAperture, CircularAnnulus#EllipticalAperture\n",
    "from photutils import aperture_photometry\n",
    "\n",
    "def compute_aperphot(cube):\n",
    "    pos   = cube[:2]\n",
    "    radius= 2#cube[2]\n",
    "    flux_aper = CircularAperture(pos, radius)\n",
    "    bkg_aper  = CircularAnnulus(pos, r_in=10*radius, r_out=20*radius)\n",
    "    #apertures = EllipticalAperture(pos, ywidth, xwidht, theta)\n",
    "    modelNow  = model(cube)(ydata,xdata)\n",
    "    zDataNow  = zdata*modelNow\n",
    "    bkg_phot  = aperture_photometry(zDataNow, bkg_aper            , \\\n",
    "                                    error=None, mask=None       , \\\n",
    "                                    method='exact', subpixels=5 , \\\n",
    "                                    unit=None, wcs=None)['aperture_sum']\n",
    "\n",
    "    # calc relative background inside flux aperture\n",
    "    bkg_level    = bkg_phot * flux_aper.area() / bkg_aper.area()\n",
    "    \n",
    "    flux      = aperture_photometry(zDataNow, flux_aper         , \\\n",
    "                                    error=None, mask=None       , \\\n",
    "                                    method='exact', subpixels=5 , \\\n",
    "                                    unit=None, wcs=None)['aperture_sum']\n",
    "    \n",
    "    return flux.data - bkg_level.data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "# model = sine_wave; parameters = [\"amp\", \"period\"]\n",
    "# model = gaussian1D; parameters = [\"center\", \"width\"]\n",
    "# model = straight_line; parameters = [\"offset\", \"slope\"]\n",
    "\n",
    "def prior(cube, ndim, nparams):\n",
    "    cube[0] = cube[0]*xmax\n",
    "    cube[1] = cube[1]*ymax\n",
    "    cube[2] = cube[2] + 0.5 # 0.5 - 1.5\n",
    "#     cube[3] = cube[3]*2\n",
    "#     cube[4] = cube[4]*20\n",
    "#     cube[5] = cube[5]*10\n",
    "    return cube\n",
    "\n",
    "from photutils import CircularAperture, CircularAnnulus#EllipticalAperture\n",
    "from photutils import aperture_photometry\n",
    "\n",
    "def compute_aperphot(cube):\n",
    "    pos   = cube[:2]\n",
    "    radius= cube[2]\n",
    "    flux_aper = CircularAperture(pos, radius)\n",
    "    bkg_aper  = CircularAnnulus(pos, r_in=10*radius, r_out=20*radius)\n",
    "    #apertures = EllipticalAperture(pos, ywidth, xwidht, theta)\n",
    "    modelNow  = model(cube)(ydata,xdata)\n",
    "    zDataNow  = zdata*modelNow\n",
    "    bkg_phot  = aperture_photometry(zDataNow, bkg_aper            , \\\n",
    "                                    error=None, mask=None       , \\\n",
    "                                    method='exact', subpixels=5 , \\\n",
    "                                    unit=None, wcs=None)['aperture_sum']\n",
    "\n",
    "    # calc relative background inside flux aperture\n",
    "    bkg_level    = bkg_phot * flux_aper.area() / bkg_aper.area()\n",
    "    \n",
    "    flux      = aperture_photometry(zDataNow, flux_aper         , \\\n",
    "                                    error=None, mask=None       , \\\n",
    "                                    method='exact', subpixels=5 , \\\n",
    "                                    unit=None, wcs=None)['aperture_sum']\n",
    "    return flux.data - bkg_level.data\n",
    "\n",
    "def subframe(dataIn, cube, nSig=10):\n",
    "    ycenter = cube[0]\n",
    "    xcenter = cube[1]\n",
    "    width   = cube[2]\n",
    "    \n",
    "    dataNow  = dataIn.copy()\n",
    "    ycenter  = np.int(np.round(ycenter))\n",
    "    xcenter  = np.int(np.round(xcenter))\n",
    "    width    = np.int(np.round(width))\n",
    "    \n",
    "    ylower = max([ycenter - nSig*width,0])\n",
    "    yupper = min([ycenter + nSig*width, ydata.max()])\n",
    "    xlower = max([xcenter - nSig*width,0])\n",
    "    xupper = min([xcenter + nSig*width, ydata.max()])\n",
    "    \n",
    "    return dataNow[ylower:yupper, xlower:xupper]\n",
    "\n",
    "aper_rad_store = []\n",
    "def loglike(cube, ndim, nparams):\n",
    "    modelNow  = model(cube)(subframe(ydata, cube),subframe(xdata, cube))\n",
    "    aper_rad_store.append([cube, compute_aperphot(cube)])\n",
    "    return -0.5*((modelNow - subframe(zdata, cube))**2. / subframe(yuncs,cube)**2.).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zero Weighted Chisq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subzeroframe(dataIn, cube, nSig=10):\n",
    "    dataNow = zeros(dataIn.shape) + median(dataIn)\n",
    "    ycenter = cube[0]\n",
    "    xcenter = cube[1]\n",
    "    ywidth  = maxwidth#cube[2]\n",
    "    xwidth  = maxwidth#cube[3]\n",
    "    \n",
    "    ycenter = np.int(np.round(ycenter))\n",
    "    xcenter = np.int(np.round(xcenter))\n",
    "    ywidth  = np.int(np.round(ywidth))\n",
    "    xwidth  = np.int(np.round(xwidth))\n",
    "    \n",
    "    ylower = max([ycenter - nSig*ywidth,0])\n",
    "    yupper = min([ycenter + nSig*ywidth, ydata.max()])\n",
    "    xlower = max([xcenter - nSig*xwidth,0])\n",
    "    xupper = min([xcenter + nSig*xwidth, xdata.max()])\n",
    "    \n",
    "    dataNow[ylower:yupper, xlower:xupper] = dataIn[ylower:yupper, xlower:xupper]\n",
    "    \n",
    "    return dataNow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our probability functions\n",
    "# Taken from the eggbox problem.\n",
    "# model = sine_wave; parameters = [\"amp\", \"period\"]\n",
    "# model = gaussian1D; parameters = [\"center\", \"width\"]\n",
    "# model = straight_line; parameters = [\"offset\", \"slope\"]\n",
    "\n",
    "def prior(cube, ndim, nparams):\n",
    "    # centers\n",
    "    cube[0] = cube[0]*xmax\n",
    "    cube[1] = cube[1]*ymax\n",
    "    \n",
    "    # widths\n",
    "    cube[2] = cube[2] + 0.5 # 0.5 - 1.5\n",
    "    cube[3] = cube[3] + 0.5 # 0.5 - 1.5\n",
    "    \n",
    "    # heights\n",
    "    cube[4] = cube[4]*maxheight*1.1 + minheight*0.9\n",
    "    cube[5] = 10**(cube[5]*8-7) # 10**-7 - 10**1 = 0.000001 - 10\n",
    "    return cube\n",
    "\n",
    "aper_rad_store = []\n",
    "def loglike(cube, ndim, nparams):\n",
    "    modelNow  = model(cube)(ydata,xdata)\n",
    "    aper_rad_store.append([cube, compute_aperphot(cube)])\n",
    "    # print(-0.5*((modelNow - zdata)**2. / zerr**2.).sum())\n",
    "    return -0.5*((modelNow - zdata)**2. / zerr**2.).sum()# / (modelNow**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos   = paramsNow[:2]\n",
    "radius= 2#paramsNow[2]\n",
    "flux_aper = CircularAperture(pos, radius)\n",
    "bkg_aper  = CircularAnnulus(pos, r_in=10*radius, r_out=20*radius)\n",
    "#apertures = EllipticalAperture(pos, ywidth, xwidht, theta)\n",
    "\n",
    "bkg_phot    = aperture_photometry(zdata, bkg_aper            , \\\n",
    "                                error=None, mask=None       , \\\n",
    "                                method='exact', subpixels=5 , \\\n",
    "                                unit=None, wcs=None)['aperture_sum']\n",
    "\n",
    "# calc relative background inside flux aperture\n",
    "bkg_level    = bkg_phot * flux_aper.area() / bkg_aper.area()\n",
    "\n",
    "flux      = aperture_photometry(zdata, flux_aper            , \\\n",
    "                                error=None, mask=None       , \\\n",
    "                                method='exact', subpixels=5 , \\\n",
    "                                unit=None, wcs=None)['aperture_sum']\n",
    "\n",
    "#modelNow = model(cube)(ydata,xdata)\n",
    "print((flux.data - bkg_level.data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(parameters))\n",
    "ndim = 2\n",
    "print(loglike(paramsNow, ndim, len(parameters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import os, pymultinest\n",
    "# from time import time\n",
    "if not os.path.exists(\"chains\"): os.mkdir(\"chains\")\n",
    "\n",
    "# number of dimensions our problem has\n",
    "# parameters = [\"x\", \"y\"]\n",
    "n_params = len(parameters)\n",
    "\n",
    "outputfiles_basename='chains/2-'\n",
    "\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "# we want to see some output while it is running\n",
    "\n",
    "start = time()\n",
    "progress = pymultinest.ProgressPlotter(n_params = n_params, outputfiles_basename=outputfiles_basename); progress.start()\n",
    "# threading.Timer(2, show, [\"chains/2-phys_live.points.pdf\"]).start() # delayed opening\n",
    "# run MultiNest\n",
    "pymultinest.run(loglike, prior, n_params, importance_nested_sampling = False, \\\n",
    "                resume = False, verbose = True, sampling_efficiency = 'model', n_live_points = 2000, \\\n",
    "                outputfiles_basename=outputfiles_basename, max_modes=100, max_iter=int(2e5))\n",
    "\n",
    "'''\n",
    "sampling_efficiency == 'parameter' for parameter estimation\n",
    "sampling_efficiency == 'model'     for model selection\n",
    "'''\n",
    "\n",
    "# ok, done. Stop our progress watcher\n",
    "progress.stop()\n",
    "print('This operation took ', time()-start,'seconds')\n",
    "# lets analyse the results\n",
    "a = pymultinest.Analyzer(n_params = n_params, outputfiles_basename=outputfiles_basename)\n",
    "s = a.get_stats()\n",
    "\n",
    "# fig = gcf()\n",
    "# axs  = fig.get_axes()\n",
    "# for ax in axs:\n",
    "#     ax.set_ylim(-16,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# store name of parameters, always useful\n",
    "with open('%sparams.json' % a.outputfiles_basename, 'w') as f:\n",
    "    json.dump(parameters, f, indent=2)\n",
    "# store derived stats\n",
    "with open('%sstats.json' % a.outputfiles_basename, mode='w') as f:\n",
    "    json.dump(s, f, indent=2)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 30, 'ANALYSIS', \"-\" * 30)\n",
    "print(\"Global Evidence:\\n\\t%.15e +- %.15e\" % ( s['nested sampling global log-evidence'], s['nested sampling global log-evidence error'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "\n",
    "# Here we will plot all the marginals and whatnot, just to show off\n",
    "# You may configure the format of the output here, or in matplotlibrc\n",
    "# All pymultinest does is filling in the data of the plot.\n",
    "\n",
    "# Copy and edit this file, and play with it.\n",
    "\n",
    "p = pymultinest.PlotMarginalModes(a)\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "#plt.subplots_adjust(wspace=0, hspace=0)\n",
    "for i in range(n_params):\n",
    "    plt.subplot(n_params, n_params, n_params * i + i + 1)\n",
    "    p.plot_marginal(i, with_ellipses = True, with_points = False, grid_points=50)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    \n",
    "    for j in range(i):\n",
    "        plt.subplot(n_params, n_params, n_params * j + i + 1)\n",
    "        #plt.subplots_adjust(left=0, bottom=0, right=0, top=0, wspace=0, hspace=0)\n",
    "        p.plot_conditional(i, j, with_ellipses = False, with_points = True, grid_points=30)\n",
    "        plt.xlabel(parameters[i])\n",
    "        plt.ylabel(parameters[j])\n",
    "\n",
    "# plt.savefig(\"chains/marginals_multinest.pdf\") #, bbox_inches='tight')\n",
    "# show(\"chains/marginals_multinest.pdf\")\n",
    "\n",
    "plt.figure(figsize=(5*n_params, 5*n_params))\n",
    "plt.subplot2grid((5*n_params, 5*n_params), loc=(0,0))\n",
    "for i in range(n_params):\n",
    "    #plt.subplot(n_params, n_params, i + 1)\n",
    "    # outfile = '%s-mode-marginal-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p.plot_modes_marginal(i, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "    \n",
    "    # outfile = '%s-mode-marginal-cumulative-%d.pdf' % (a.outputfiles_basename,i)\n",
    "    p.plot_modes_marginal(i, cumulative = True, with_ellipses = True, with_points = False)\n",
    "    plt.ylabel(\"Cumulative probability\")\n",
    "    plt.xlabel(parameters[i])\n",
    "    # plt.savefig(outfile, format='pdf', bbox_inches='tight')\n",
    "    # plt.close()\n",
    "\n",
    "# print(\"Take a look at the pdf files in chains/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('best\\t\\t', np.round(p.analyser.get_best_fit()['parameters'],3))\n",
    "for k,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    print('mode {0:d}\\t\\t'.format(k), np.round(mode['mean'],3),'\\t', np.round(mode['local log-evidence'],3))\n",
    "\n",
    "for kp, paramsNow in enumerate(paramsList):\n",
    "    print('True Mode {0:d}\\t'.format(kp), np.round(paramsNow,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 20\n",
    "for km,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    for kp, paramsNow in enumerate(paramsList):\n",
    "        if (sum((array(paramsNow) - mode['mean'])**2.) < thresh):\n",
    "            print(kp)\n",
    "            print(paramsNow)\n",
    "            print(mode['mean'])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelAll = np.zeros((nPts, nPts))\n",
    "fig=figure(figsize=(20,10))\n",
    "for km,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    modelAll = modelAll + model(mode['mean'])(ydata,xdata)\n",
    "    ax = fig.add_subplot(1,len(p.analyser.get_stats()['modes']), km+1)\n",
    "    ims = ax.imshow(model(mode['mean'])(ydata,xdata))\n",
    "    divider  = make_axes_locatable(ax)\n",
    "    cax      = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar     = plt.colorbar(ims, cax=cax, ticks=MultipleLocator(1), format=\"%.2f\")\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(131)\n",
    "ims = ax.imshow(modelAll)\n",
    "divider  = make_axes_locatable(ax)\n",
    "cax      = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar     = plt.colorbar(ims, cax=cax, ticks=MultipleLocator(1), format=\"%.2f\")\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(132)\n",
    "ims = ax.imshow(model(p.analyser.get_best_fit()['parameters'])(ydata,xdata))\n",
    "divider  = make_axes_locatable(ax)\n",
    "cax      = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar     = plt.colorbar(ims, cax=cax, ticks=MultipleLocator(1), format=\"%.2f\")\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(133)\n",
    "ims = ax.imshow(zdata)\n",
    "divider  = make_axes_locatable(ax)\n",
    "cax      = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar     = plt.colorbar(ims, cax=cax, ticks=MultipleLocator(1), format=\"%.2f\")\n",
    "\n",
    "# Residuals\n",
    "modelAll = np.zeros((nPts, nPts))\n",
    "for km,mode in enumerate(p.analyser.get_stats()['modes']):\n",
    "    print(km, loglike(mode['mean'], 2, 3))\n",
    "    if np.round(mode['local log-evidence'],3) > -400000.:\n",
    "        modelAll = modelAll + model(mode['mean'])(ydata,xdata)\n",
    "\n",
    "fig = figure(figsize=(20,10))\n",
    "ax  = fig.add_subplot(131)\n",
    "ims = ax.imshow(zdata - (modelAll - median(modelAll)))\n",
    "divider  = make_axes_locatable(ax)\n",
    "cax      = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar     = plt.colorbar(ims, cax=cax, ticks=MultipleLocator(1), format=\"%.2f\")\n",
    "\n",
    "ax  = fig.add_subplot(132, aspect='equal')\n",
    "ax.hist((zdata - (modelAll - median(modelAll))).ravel(), bins=50, normed=True);\n",
    "ax.axvline(0.0, ls='--', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p.analyser.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
